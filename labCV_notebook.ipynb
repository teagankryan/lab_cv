{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEdu5oVED5SQ"
      },
      "source": [
        "## Computer Vision\n",
        "\n",
        "Let's do some very basic computer vision. We're going to import the MNIST handwritten digits data and $k$NN to predict values (i.e. \"see/read\").\n",
        "\n",
        "1. To load the data, run the following code in a chunk:\n",
        "```\n",
        "import pickle\n",
        "with open('data/minst.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "X_train, y_train = data['X_train'], data['y_train']\n",
        "X_test, y_test = data['X_test'], data['y_test']\n",
        "```\n",
        "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()\n",
        "```\n",
        "OK, those are the data: Labels attached to handwritten digits encoded as a matrix. OUR ANSWERS ARE BELOW IN CODE CHUNKS\n",
        "\n",
        "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
        "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
        "4. Use the reshaped `X_test` and `y_test` data to create a $k$-nearest neighbor classifier of digit. What is the optimal number of neighbors $k$? If you can't determine this, play around with different values of $k$ for your classifier.\n",
        "5. For the optimal number of neighbors, how well does your predictor perform on the test set? Report the accuracy, compute a confusion matrix, and explain your findings.\n",
        "6. For your confusion matrix, which mistakes are most likely? Do you find any interesting patterns?\n",
        "7. So, this is how computers \"see.\" They convert an image into a matrix of values, that matrix becomes a vector in a dataset, and then we deploy ML tools on it as if it was any other kind of tabular data. To make sure you follow this, invent a way to represent a color photo in matrix form, and then describe how you could convert it into tabular data. (Hint: RGB color codes provide a method of encoding a numeric value that represents a color.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1:\n",
        "\n",
        "import pickle\n",
        "with open('/content/minst.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "X_train, y_train = data['X_train'], data['y_train']\n",
        "X_test, y_test = data['X_test'], data['y_test']"
      ],
      "metadata": {
        "id": "b2ABnjthD7zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "77fb7030-460b-4d85-a514-cf77698790c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/minst.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3825412507.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/minst.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/minst.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc3SZiEMD5SS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2:\n",
        "# What is the shape of X_train and X_test?\n",
        "# What is the shape of X_train[i] and X_test[i] for each index i?\n",
        "# What is the shape of y_train and y_test?\n",
        "\n",
        "print(X_train.shape , X_test.shape)\n",
        "\n",
        "print(X_train[3].shape , X_test[3].shape) # Same shape for all index i\n",
        "\n",
        "print(y_train.shape , y_test.shape)\n"
      ],
      "metadata": {
        "id": "xSsx9GteFDTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3:\n",
        "# Use Numpy's .reshape() method to covert the training and testing data from a matrix into an vector of features.\n",
        "# So, X_test[index].reshape((1,784)) will convert the  ùëñùëõùëëùëíùë• -th element of X_test into a  28√ó28=784 -length row vector of values, rather than a matrix.\n",
        "# Turn X_train into an  ùëÅ√ó784  matrix  ùëã  that is suitable for scikit-learn's kNN classifier where  ùëÅ  is the number of observations and  784=28‚àó28 (you could use, for example, a for loop).\n",
        "\n",
        "X_train = X_train.reshape((60000,784))\n",
        "X_test = X_test.reshape((10000,784))"
      ],
      "metadata": {
        "id": "gxnhnaGbGvFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4:\n",
        "# Use the reshaped X_test and y_test data to create a  ùëò -nearest neighbor classifier of digit.\n",
        "# What is the optimal number of neighbors  ùëò ?\n",
        "# If you can't determine this, play around with different values of  ùëò  for your classifier.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "N_train = len(y_train)\n",
        "N_test = len(y_test)\n",
        "\n",
        "## Solve for k that maximizes accuracy:\n",
        "k_bar = 10 # Number of k's to try\n",
        "Acc = [] # We'll store the accuracy here\n",
        "\n",
        "for k in range(k_bar):\n",
        "    model = KNeighborsClassifier(n_neighbors=k+1) # Create a sk model for k\n",
        "    fitted_model = model.fit(X_train,y_train) # Train the model on our data\n",
        "    y_hat = fitted_model.predict(X_test) # Predict values for test set\n",
        "    Acc.append( np.sum( y_hat == y_test )/N_test ) # Accuracy on testing data\n",
        "\n",
        "Acc_max = np.max(Acc) # Find highest recorded Accuracy\n",
        "max_index = np.where(Acc==Acc_max) # Find the indices that equal the maximum\n",
        "k_star = max_index[0]+1 # Find the optimal value of k; why index+1?\n",
        "print(k_star)"
      ],
      "metadata": {
        "id": "WJCSAc9DIEZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5:\n",
        "# For the optimal number of neighbors, how well does your predictor perform on the test set?\n",
        "# Report the accuracy, compute a confusion matrix, and explain your findings.\n",
        "\n",
        "## Fit optimal model:\n",
        "model = KNeighborsClassifier(n_neighbors=k_star[0]) # Create a sk model for k\n",
        "fitted_model = model.fit(X_train,y_train) # Train the model on our data\n",
        "y_hat = fitted_model.predict(X_test) # Predict values for test set\n"
      ],
      "metadata": {
        "id": "8COeP458QjdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(y_test, y_hat)\n",
        "print(acc)\n",
        "\n",
        "import pandas as pd\n",
        "pd.crosstab(y_test,y_hat)"
      ],
      "metadata": {
        "id": "RF-1hkIaRUd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictor performs very well on the test set with an accuracy of 97.05%. From the confusion matrix we can see that the model frequently makes the correct prediction, the diagonal entries are far more populated than the off-diagonals, incorrect categorizations."
      ],
      "metadata": {
        "id": "CIV29KgUR0ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. For your confusion matrix, which mistakes are most likely? Do you find any interesting patterns?\n",
        "\n",
        "The most common confusion is mistaking a 7 for a 1 with 21 incorrect predictions, follow by categorizing a 4 as a 9 with 19 wrong cases. Also, it seems like the numbers 8 and 9 are most oftenly mistaken for other numbers.\n",
        "\n"
      ],
      "metadata": {
        "id": "_G-f3HyCSkvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. So, this is how computers \"see.\" They convert an image into a matrix of values, that matrix becomes a vector in a dataset, and then we deploy ML tools on it as if it was any other kind of tabular data. To make sure you follow this, invent a way to represent a color photo in matrix form, and then describe how you could convert it into tabular data. (Hint: RGB color codes provide a method of encoding a numeric value that represents a color.)"
      ],
      "metadata": {
        "id": "Tn9s2fWf5-nR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A way we could represent a color photo in matrix form is to determine each pixels' RGB values (0-255) and create a vector based on the intensity of each color. Turning this into tabular data is relatively straight forward. We could make each pixel in the photo a row and have \"Red\", \"Green\", and \"Blue\", as in RGB, be the columns. Each mix of RBG relates to a different color. For example, a pixel may have the RBG mix of (23,230,165) and another pixel might have a RGB mix of (145,46,67) which relates to a different color."
      ],
      "metadata": {
        "id": "21f0J2ki7RAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For example-$10x10 color image (100 pixels)\n",
        "import numpy as np\n",
        "image = np.random.randint(0, 256, (10, 10, 3))\n",
        "\n",
        "print(\"Original shape:\", image.shape)      # (10, 10, 3)\n",
        "\n",
        "# Flatten to one row (vector)\n",
        "flat = image.reshape(1, 10*10*3)\n",
        "print(\"Flattened shape:\", flat.shape)      # (1, 300)\n",
        "\n",
        "# Or tabular form: 100 rows, 3 columns (each pixel as row)\n",
        "tabular = image.reshape(100, 3)\n",
        "print(\"Tabular shape:\", tabular.shape)     # (100, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W30vIQZZ97UE",
        "outputId": "78380947-9721-49d6-fd40-d8c17b877345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (10, 10, 3)\n",
            "Flattened shape: (1, 300)\n",
            "Tabular shape: (100, 3)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}